{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63801d20-d583-4b2e-a1ea-8c626c605e9d",
   "metadata": {},
   "source": [
    "# Supervised Learning with scikit-learn (Ridge Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b9582bf-bb0a-4f8f-b4fc-fe0f31fe4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading classes\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate, RandomizedSearchCV\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Ignoring future warnings for readability reasons\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e33f61f-c0ba-4fe9-a03c-f3fdafd3534f",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "Ridge regression introduces a penalty for each coefficient. The penalty is introduced by adding the sum of the squared coefficients of the linear regression model to the loss function. The extent of the penalty is defined by the hyperparameter alpha which is multiplied with the sum of the coefficients. It is important to know that while the coefficients of the standard OLS regression are scale invariant, those of Ridge regression aren't.\n",
    "\n",
    "The advantage of ridge regression over OLS is that to some extent ridge regression reduces the variance of the predictionms at cost at the expense of a slightly increased bias.\n",
    "\n",
    "In the following example, riddge regression is applied on sales data using expenditure for different media channels. First, I apply ridge regression with alpha = 0.5 and non standardized data. Then, I standardize the data and show that coefficients differ. Finally, I apply randomized search cross to hyptertune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb649156-b5ee-4993-8880-117c35ba0f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tv</th>\n",
       "      <th>radio</th>\n",
       "      <th>social_media</th>\n",
       "      <th>influencer</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16000.0</td>\n",
       "      <td>6566.23</td>\n",
       "      <td>2907.98</td>\n",
       "      <td>Mega</td>\n",
       "      <td>54732.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13000.0</td>\n",
       "      <td>9237.76</td>\n",
       "      <td>2409.57</td>\n",
       "      <td>Mega</td>\n",
       "      <td>46677.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41000.0</td>\n",
       "      <td>15886.45</td>\n",
       "      <td>2913.41</td>\n",
       "      <td>Mega</td>\n",
       "      <td>150177.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83000.0</td>\n",
       "      <td>30020.03</td>\n",
       "      <td>6922.30</td>\n",
       "      <td>Mega</td>\n",
       "      <td>298246.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>8437.41</td>\n",
       "      <td>1406.00</td>\n",
       "      <td>Micro</td>\n",
       "      <td>56594.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tv     radio  social_media influencer      sales\n",
       "0  16000.0   6566.23       2907.98       Mega   54732.76\n",
       "1  13000.0   9237.76       2409.57       Mega   46677.90\n",
       "2  41000.0  15886.45       2913.41       Mega  150177.83\n",
       "3  83000.0  30020.03       6922.30       Mega  298246.34\n",
       "4  15000.0   8437.41       1406.00      Micro   56594.18"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "sales_df = pd.read_csv(\"datasets/advertising_and_sales_clean.csv\")\n",
    "\n",
    "# Preview data\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aab19f5f-9a71-49ec-9436-7608bd5815b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 3.56337681e+00 -2.63637135e-03 -1.40534040e-02]\n",
      "Mean Squared Error (Ridge regression, alpha = 0.5): 8321632.178943878\n",
      "R2 squared (Ridge regression, alpha = 0.5): 0.9990105552987842\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into X matrix and y vector\n",
    "X = sales_df.drop([\"sales\", \"influencer\"], axis = 1).values\n",
    "y = sales_df[\"sales\"].values\n",
    "\n",
    "# Splitting data into train and test sample\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Initialize Ridge regression model\n",
    "ridge = Ridge(alpha = 0.5)\n",
    "\n",
    "# Train model\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "# Compute MSE and R2 squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Coefficients: {}\".format(ridge.coef_))\n",
    "print(\"Mean Squared Error (Ridge regression, alpha = 0.5): {}\".format(mse))\n",
    "print(\"R2 squared (Ridge regression, alpha = 0.5): {}\".format(r2_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30654f0-5816-4e11-93a7-c6d2542c763e",
   "metadata": {},
   "source": [
    "The preprocessing library of scikit-learn includes the StandardScaler() which standardizes numerical data to zero mean and standard deviation 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "335667da-600f-4542-9fe2-3155ce95a642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[ 9.99345684e-01  2.13618293e-04 -3.30236246e-04]]\n",
      "Mean Squared Error (Ridge regression, alpha = 0.5): 0.000988322344493767\n",
      "R2 squared (Ridge regression, alpha = 0.5): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ridge regression model\n",
    "ridge_std = Ridge(alpha = 0.5)\n",
    "\n",
    "# Standardizing data (note that I do not use the pipe here which would be more efficient on purpose)\n",
    "X_train_scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_test_scaler  = preprocessing.StandardScaler().fit(X_test)\n",
    "y_train_scaler = preprocessing.StandardScaler().fit(y_train.reshape(-1, 1))\n",
    "y_test_scaler  = preprocessing.StandardScaler().fit(y_test.reshape(-1, 1))\n",
    "\n",
    "X_train_std    = X_train_scaler.transform(X_train)\n",
    "X_test_std     = X_test_scaler.transform(X_test)\n",
    "y_train_std    = y_train_scaler.transform(y_train.reshape(-1, 1))\n",
    "y_test_std     = y_test_scaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Train model\n",
    "ridge_std.fit(X_train_std, y_train_std)\n",
    "\n",
    "# Prediction\n",
    "y_pred_std = ridge_std.predict(X_test_std)\n",
    "\n",
    "# Compute MSE and R2 squared\n",
    "mse = mean_squared_error(y_test_std, y_pred_std)\n",
    "r2_squared = r2_score(y_pred_std, y_pred_std)\n",
    "\n",
    "# Print results\n",
    "print(\"Coefficients: {}\".format(ridge_std.coef_))\n",
    "print(\"Mean Squared Error (Ridge regression, alpha = 0.5): {}\".format(mse))\n",
    "print(\"R2 squared (Ridge regression, alpha = 0.5): {}\".format(r2_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca312523-f6dd-4ea3-8b6e-762d2a43d6a0",
   "metadata": {},
   "source": [
    "As stated above, coefficients differ when using standardized data since these are not scale invariant in ridge regressions. Next, I apply randomized search cross validation to hypertune alpha eventhough the fit is very good since we know that the larger alpha is, the more biased the model is. Therefore, a small alpha should be preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d5d8544-e4fa-4d36-b98b-9a4849c01d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'alpha': 0.0}</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.998910</td>\n",
       "      <td>0.999010</td>\n",
       "      <td>0.999056</td>\n",
       "      <td>0.998986</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'alpha': 13.793103448275861}</td>\n",
       "      <td>0.998882</td>\n",
       "      <td>0.998820</td>\n",
       "      <td>0.998892</td>\n",
       "      <td>0.998960</td>\n",
       "      <td>0.998888</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'alpha': 15.517241379310343}</td>\n",
       "      <td>0.998860</td>\n",
       "      <td>0.998795</td>\n",
       "      <td>0.998864</td>\n",
       "      <td>0.998935</td>\n",
       "      <td>0.998863</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'alpha': 20.689655172413794}</td>\n",
       "      <td>0.998778</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.998765</td>\n",
       "      <td>0.998847</td>\n",
       "      <td>0.998773</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'alpha': 25.86206896551724}</td>\n",
       "      <td>0.998677</td>\n",
       "      <td>0.998591</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>0.998737</td>\n",
       "      <td>0.998662</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'alpha': 29.310344827586206}</td>\n",
       "      <td>0.998599</td>\n",
       "      <td>0.998503</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>0.998653</td>\n",
       "      <td>0.998576</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'alpha': 39.6551724137931}</td>\n",
       "      <td>0.998321</td>\n",
       "      <td>0.998189</td>\n",
       "      <td>0.998224</td>\n",
       "      <td>0.998354</td>\n",
       "      <td>0.998272</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'alpha': 41.37931034482759}</td>\n",
       "      <td>0.998268</td>\n",
       "      <td>0.998129</td>\n",
       "      <td>0.998163</td>\n",
       "      <td>0.998297</td>\n",
       "      <td>0.998214</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'alpha': 48.275862068965516}</td>\n",
       "      <td>0.998043</td>\n",
       "      <td>0.997873</td>\n",
       "      <td>0.997901</td>\n",
       "      <td>0.998055</td>\n",
       "      <td>0.997968</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          params  split0_test_score  split1_test_score  \\\n",
       "9                 {'alpha': 0.0}           0.998969           0.998910   \n",
       "4  {'alpha': 13.793103448275861}           0.998882           0.998820   \n",
       "5  {'alpha': 15.517241379310343}           0.998860           0.998795   \n",
       "8  {'alpha': 20.689655172413794}           0.998778           0.998704   \n",
       "1   {'alpha': 25.86206896551724}           0.998677           0.998591   \n",
       "3  {'alpha': 29.310344827586206}           0.998599           0.998503   \n",
       "2    {'alpha': 39.6551724137931}           0.998321           0.998189   \n",
       "7   {'alpha': 41.37931034482759}           0.998268           0.998129   \n",
       "6  {'alpha': 48.275862068965516}           0.998043           0.997873   \n",
       "\n",
       "   split2_test_score  split3_test_score  mean_test_score  std_test_score  \\\n",
       "9           0.999010           0.999056         0.998986        0.000054   \n",
       "4           0.998892           0.998960         0.998888        0.000050   \n",
       "5           0.998864           0.998935         0.998863        0.000050   \n",
       "8           0.998765           0.998847         0.998773        0.000051   \n",
       "1           0.998643           0.998737         0.998662        0.000053   \n",
       "3           0.998551           0.998653         0.998576        0.000056   \n",
       "2           0.998224           0.998354         0.998272        0.000068   \n",
       "7           0.998163           0.998297         0.998214        0.000070   \n",
       "6           0.997901           0.998055         0.997968        0.000082   \n",
       "\n",
       "   rank_test_score  \n",
       "9                1  \n",
       "4                2  \n",
       "5                3  \n",
       "8                4  \n",
       "1                5  \n",
       "3                6  \n",
       "2                7  \n",
       "7                8  \n",
       "6               10  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining k folds\n",
    "kf = KFold(4, random_state=42, shuffle=True)\n",
    "\n",
    "# Defining grid using randomly distributed values for alpha between 0 and 50\n",
    "param_grid = {'alpha': np.linspace(0, 50, num=30)}\n",
    "\n",
    "# Initializing a new model\n",
    "ridge = Ridge()\n",
    "\n",
    "# Defining Randomized Search CV\n",
    "ridge_cv = RandomizedSearchCV(ridge, param_grid, cv = kf, random_state = 42, n_iter = 10)\n",
    "\n",
    "# Fitting model using standardized train and test data\n",
    "ridge_cv.fit(X_train_std, y_train_std)\n",
    "\n",
    "# Results of GridSearchCV\n",
    "pd.DataFrame(ridge_cv.cv_results_).iloc[1:,5:].sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65148ca7-c92a-4b9f-af7c-a40b4535ad51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value: Ridge(alpha=0.0)\n",
      "Coefficients (best ridge model): [[ 9.99906362e-01 -2.73041674e-04 -3.31013519e-04]]\n",
      "Mean Squared Error (best ridge model): 0.0009884330608730249\n",
      "R2 squared (best ridge model): 0.999011566939127\n"
     ]
    }
   ],
   "source": [
    "# Predictions for best model from RandomizedSearchCV\n",
    "y_pred_std_ridge_cv = ridge_cv.predict(X_test_std)\n",
    "\n",
    "# Compute MSE and R2 squared\n",
    "mse = mean_squared_error(y_test_std, y_pred_std_ridge_cv)\n",
    "r2_squared = r2_score(y_test_std, y_pred_std_ridge_cv)\n",
    "\n",
    "# Print results\n",
    "print(\"Best alpha value: {}\".format(ridge_cv.best_estimator_))\n",
    "print(\"Coefficients (best ridge model): {}\".format(ridge_cv.best_estimator_.coef_))\n",
    "print(\"Mean Squared Error (best ridge model): {}\".format(mse))\n",
    "print(\"R2 squared (best ridge model): {}\".format(r2_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba74cff-46a8-4f7b-8a7c-b67c1e093065",
   "metadata": {},
   "source": [
    "Interestingly, the best model is the model where alpha equals zero, which is the standard OLS regression model. For comparison, the standard linear regression is fitted and compared to the ridge model with alpha = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24a84d82-b5c6-46ba-ba1a-7b3737a9476f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[ 9.99906362e-01 -2.73041674e-04 -3.31013519e-04]]\n",
      "Mean Squared Error: 0.0009884330608730227\n",
      "R2 squared: 0.999011566939127\n"
     ]
    }
   ],
   "source": [
    "# Initializing linear model\n",
    "ols = LinearRegression()\n",
    "\n",
    "# Model training\n",
    "ols.fit(X_train_std, y_train_std)\n",
    "\n",
    "# Computing predictions with test data\n",
    "y_pred_std_ols = ols.predict(X_test_std)\n",
    "\n",
    "# Compute MSE and R2 squared\n",
    "mse = mean_squared_error(y_test_std, y_pred_std_ols)\n",
    "r2_squared = r2_score(y_test_std, y_pred_std_ols)\n",
    "\n",
    "# Print results\n",
    "print(\"Coefficients: {}\".format(ols.coef_))\n",
    "print(\"Mean Squared Error: {}\".format(mse))\n",
    "print(\"R2 squared: {}\".format(r2_squared))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
