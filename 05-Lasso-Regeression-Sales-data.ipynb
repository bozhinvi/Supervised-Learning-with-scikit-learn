{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "153ea198-0741-4e34-9b7a-6c4ab9e90cb4",
   "metadata": {},
   "source": [
    "# Supervised Learning with scikit-learn (Lasso Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b48622e2-47dd-4a9a-940d-c274b26945a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading classes\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate, RandomizedSearchCV\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Ignoring future warnings for readability reasons\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750a0b1-e542-4682-85b3-e64c75f5f13f",
   "metadata": {},
   "source": [
    "# Lasso Regression\n",
    "\n",
    "Ridge regression introduces a penalty for each coefficient. The penalty is introduced by adding the sum of the absolute value of the squared coefficients of the linear regression model to the loss function. The extent of the penalty is defined by the hyperparameter alpha which is multiplied with the sum of the coefficients. It is important to know that while the coefficients of the standard OLS regression are scale invariant, those of Lasso regression aren't which is the same like when applying Ridge regression.\n",
    "\n",
    "The advantage of Lasse regression over OLS is that to some extent ridge regression reduces the variance of the predictionms at cost at the expense of a slightly increased bias. Furthermore, in contrast to Ridge, the Lasso can rule out some of the coeffients completely and can therefore be used for feature selection and reduction.\n",
    "\n",
    "In the following example, Lasso regression is applied on sales data using expenditure for different media channels. First, I apply Lasso regression with alpha = 0.5 and non standardized data. Then, I standardize the data and show that coefficients differ. Finally, I apply randomized search cross to hyptertune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b72865fe-2ef6-4b1e-aaed-9b4b90ca5e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tv</th>\n",
       "      <th>radio</th>\n",
       "      <th>social_media</th>\n",
       "      <th>influencer</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16000.0</td>\n",
       "      <td>6566.23</td>\n",
       "      <td>2907.98</td>\n",
       "      <td>Mega</td>\n",
       "      <td>54732.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13000.0</td>\n",
       "      <td>9237.76</td>\n",
       "      <td>2409.57</td>\n",
       "      <td>Mega</td>\n",
       "      <td>46677.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41000.0</td>\n",
       "      <td>15886.45</td>\n",
       "      <td>2913.41</td>\n",
       "      <td>Mega</td>\n",
       "      <td>150177.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83000.0</td>\n",
       "      <td>30020.03</td>\n",
       "      <td>6922.30</td>\n",
       "      <td>Mega</td>\n",
       "      <td>298246.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>8437.41</td>\n",
       "      <td>1406.00</td>\n",
       "      <td>Micro</td>\n",
       "      <td>56594.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tv     radio  social_media influencer      sales\n",
       "0  16000.0   6566.23       2907.98       Mega   54732.76\n",
       "1  13000.0   9237.76       2409.57       Mega   46677.90\n",
       "2  41000.0  15886.45       2913.41       Mega  150177.83\n",
       "3  83000.0  30020.03       6922.30       Mega  298246.34\n",
       "4  15000.0   8437.41       1406.00      Micro   56594.18"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "sales_df = pd.read_csv(\"datasets/advertising_and_sales_clean.csv\")\n",
    "\n",
    "# Preview data\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7bad59bc-4797-4e2c-a6df-3c85eb5762ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 3.56337679e+00 -2.63635719e-03 -1.40532634e-02]\n",
      "Mean Squared Error (Lasso regression, alpha = 0.5): 8321632.083843608\n",
      "R2 squared (Lasso regression, alpha = 0.5): 0.9990105553100916\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into X matrix and y vector\n",
    "X = sales_df.drop([\"sales\", \"influencer\"], axis = 1).values\n",
    "y = sales_df[\"sales\"].values\n",
    "\n",
    "# Splitting data into train and test sample\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Initialize Ridge regression model\n",
    "lasso = Lasso(alpha = 0.5)\n",
    "\n",
    "# Train model\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "# Compute MSE and R2 squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Coefficients: {}\".format(lasso.coef_))\n",
    "print(\"Mean Squared Error (Lasso regression, alpha = 0.5): {}\".format(mse))\n",
    "print(\"R2 squared (Lasso regression, alpha = 0.5): {}\".format(r2_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2826e3b-c8e2-42ec-bc23-80a1330f0b2f",
   "metadata": {},
   "source": [
    "The preprocessing library of scikit-learn includes the StandardScaler() which standardizes numerical data to zero mean and standard deviation 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "723879c3-5b15-4ce0-8519-c3d43df138a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tv</th>\n",
       "      <th>radio</th>\n",
       "      <th>social_media</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.458233</td>\n",
       "      <td>-1.199655</td>\n",
       "      <td>-0.187920</td>\n",
       "      <td>-1.480283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.573167</td>\n",
       "      <td>-0.923162</td>\n",
       "      <td>-0.413342</td>\n",
       "      <td>-1.566885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.500455</td>\n",
       "      <td>-0.235048</td>\n",
       "      <td>-0.185464</td>\n",
       "      <td>-0.454098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.108613</td>\n",
       "      <td>1.227723</td>\n",
       "      <td>1.627684</td>\n",
       "      <td>1.137871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.496545</td>\n",
       "      <td>-1.005995</td>\n",
       "      <td>-0.867238</td>\n",
       "      <td>-1.460270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tv     radio  social_media     sales\n",
       "0 -1.458233 -1.199655     -0.187920 -1.480283\n",
       "1 -1.573167 -0.923162     -0.413342 -1.566885\n",
       "2 -0.500455 -0.235048     -0.185464 -0.454098\n",
       "3  1.108613  1.227723      1.627684  1.137871\n",
       "4 -1.496545 -1.005995     -0.867238 -1.460270"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Ridge regression model\n",
    "lasso_std = Lasso(alpha = 0.5)\n",
    "\n",
    "# Standardizing Data\n",
    "data_df_scaler = preprocessing.StandardScaler().fit(sales_df.drop([\"influencer\"], axis = 1))\n",
    "data_df_std = pd.DataFrame(data_df_scaler.transform(sales_df.drop([\"influencer\"], axis = 1)))\n",
    "\n",
    "# Rename columns\n",
    "data_df_std.rename(columns={0: 'tv', 1: 'radio', 2: 'social_media', 3: 'sales'}, inplace=True)\n",
    "\n",
    "# Inspecting normalized data\n",
    "data_df_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d1758d16-dfc5-41e0-bde3-ae9950a571c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and create train and test dataset into X_std and y_std\n",
    "X_std = data_df_std.drop(\"sales\", axis = 1).values\n",
    "\n",
    "y_std = data_df_std[\"sales\"].values\n",
    "\n",
    "X_std_train, X_std_test, y_std_train, y_std_test = train_test_split(X_std, y_std, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "96027a70-2d2f-45ba-8dde-e479b997d6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.50292537 0.         0.        ]\n",
      "Mean Squared Error (Lasso regression, alpha = 0.5): 0.24053322885402215\n",
      "R2 squared (Lasso regression, alpha = 0.5): 0.022786049404024844\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "lasso_std.fit(X_std_train, y_std_train)\n",
    "\n",
    "# Prediction\n",
    "y_std_pred = lasso_std.predict(X_std_test)\n",
    "\n",
    "# Compute MSE and R2 squared\n",
    "mse = mean_squared_error(y_std_test, y_std_pred)\n",
    "r2_squared = r2_score(y_std_pred, y_std_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Coefficients: {}\".format(lasso_std.coef_))\n",
    "print(\"Mean Squared Error (Lasso regression, alpha = 0.5): {}\".format(mse))\n",
    "print(\"R2 squared (Lasso regression, alpha = 0.5): {}\".format(r2_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc879b-80e1-4134-a6f2-238d0d7e284e",
   "metadata": {},
   "source": [
    "As stated above, coefficients differ when using standardized data since these are not scale invariant in Lasso regressions. Interestingly, setting alpha to 0.5 eliminates two out of three features but also the R-squared is very low. Next, I apply randomized search cross validation to hypertune alpha eventhough the fit is very good since we know that the larger alpha is, the more biased the model is. Therefore, a small alpha should be preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8e7efa27-34b5-4058-9d23-7f8c296b66b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.386e+00, tolerance: 2.758e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+00, tolerance: 2.735e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e+00, tolerance: 2.771e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e+00, tolerance: 2.715e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.847e+00, tolerance: 3.661e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'alpha': 0.0}</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.998910</td>\n",
       "      <td>0.999010</td>\n",
       "      <td>9.990559e-01</td>\n",
       "      <td>0.998986</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'alpha': 15.517241379310345}</td>\n",
       "      <td>-0.013192</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>-5.608290e-09</td>\n",
       "      <td>-0.006353</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'alpha': 23.793103448275865}</td>\n",
       "      <td>-0.013192</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>-5.608290e-09</td>\n",
       "      <td>-0.006353</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'alpha': 17.586206896551726}</td>\n",
       "      <td>-0.013192</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>-5.608290e-09</td>\n",
       "      <td>-0.006353</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'alpha': 8.275862068965518}</td>\n",
       "      <td>-0.013192</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>-5.608290e-09</td>\n",
       "      <td>-0.006353</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'alpha': 9.310344827586208}</td>\n",
       "      <td>-0.013192</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>-5.608290e-09</td>\n",
       "      <td>-0.006353</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'alpha': 28.965517241379313}</td>\n",
       "      <td>-0.013192</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>-5.608290e-09</td>\n",
       "      <td>-0.006353</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'alpha': 24.827586206896555}</td>\n",
       "      <td>-0.013192</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>-5.608290e-09</td>\n",
       "      <td>-0.006353</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'alpha': 12.413793103448278}</td>\n",
       "      <td>-0.013192</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>-5.608290e-09</td>\n",
       "      <td>-0.006353</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          params  split0_test_score  split1_test_score  \\\n",
       "9                 {'alpha': 0.0}           0.998969           0.998910   \n",
       "1  {'alpha': 15.517241379310345}          -0.013192          -0.000027   \n",
       "2  {'alpha': 23.793103448275865}          -0.013192          -0.000027   \n",
       "3  {'alpha': 17.586206896551726}          -0.013192          -0.000027   \n",
       "4   {'alpha': 8.275862068965518}          -0.013192          -0.000027   \n",
       "5   {'alpha': 9.310344827586208}          -0.013192          -0.000027   \n",
       "6  {'alpha': 28.965517241379313}          -0.013192          -0.000027   \n",
       "7  {'alpha': 24.827586206896555}          -0.013192          -0.000027   \n",
       "8  {'alpha': 12.413793103448278}          -0.013192          -0.000027   \n",
       "\n",
       "   split2_test_score  split3_test_score  mean_test_score  std_test_score  \\\n",
       "9           0.999010       9.990559e-01         0.998986        0.000054   \n",
       "1          -0.012195      -5.608290e-09        -0.006353        0.006350   \n",
       "2          -0.012195      -5.608290e-09        -0.006353        0.006350   \n",
       "3          -0.012195      -5.608290e-09        -0.006353        0.006350   \n",
       "4          -0.012195      -5.608290e-09        -0.006353        0.006350   \n",
       "5          -0.012195      -5.608290e-09        -0.006353        0.006350   \n",
       "6          -0.012195      -5.608290e-09        -0.006353        0.006350   \n",
       "7          -0.012195      -5.608290e-09        -0.006353        0.006350   \n",
       "8          -0.012195      -5.608290e-09        -0.006353        0.006350   \n",
       "\n",
       "   rank_test_score  \n",
       "9                1  \n",
       "1                2  \n",
       "2                2  \n",
       "3                2  \n",
       "4                2  \n",
       "5                2  \n",
       "6                2  \n",
       "7                2  \n",
       "8                2  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining k folds\n",
    "kf = KFold(4, random_state=42, shuffle=True)\n",
    "\n",
    "# Defining grid using randomly distributed values for alpha between 0 and 50\n",
    "param_grid = {'alpha': np.linspace(0, 30, num=30)}\n",
    "\n",
    "# Initializing a new model\n",
    "lasso = Lasso()\n",
    "\n",
    "# Defining Randomized Search CV\n",
    "lasso_cv = RandomizedSearchCV(lasso, param_grid, cv = kf, random_state = 42, n_iter = 10)\n",
    "\n",
    "# Fitting model using standardized train and test data\n",
    "lasso_cv.fit(X_std_train, y_std_train)\n",
    "\n",
    "# Results of GridSearchCV\n",
    "pd.DataFrame(lasso_cv.cv_results_).iloc[1:,5:].sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b82db1d7-2e76-4853-9fcd-dc3ae69c4bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value: Lasso(alpha=0.0)\n",
      "Coefficients (best lasso model): [ 1.00002011e+00 -2.73876324e-04 -3.34075327e-04]\n",
      "Mean Squared Error (best lasso model): 0.001318411870044389\n",
      "R squared (best lasso model): 0.9986439051759302\n"
     ]
    }
   ],
   "source": [
    "# Predictions for best model from RandomizedSearchCV\n",
    "y_std_pred_lasso_cv = lasso_cv.predict(X_test_std)\n",
    "\n",
    "# Compute MSE and R2 squared\n",
    "mse = mean_squared_error(y_std_test, y_std_pred_lasso_cv)\n",
    "r2_squared = r2_score(y_std_test, y_std_pred_lasso_cv)\n",
    "\n",
    "# Print results\n",
    "print(\"Best alpha value: {}\".format(lasso_cv.best_estimator_))\n",
    "print(\"Coefficients (best lasso model): {}\".format(lasso_cv.best_estimator_.coef_))\n",
    "print(\"Mean Squared Error (best lasso model): {}\".format(mse))\n",
    "print(\"R squared (best lasso model): {}\".format(r2_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de7baf-73a3-4d6d-9fc0-6559debd1633",
   "metadata": {},
   "source": [
    "Interestingly, the warnings indicate that there is a convergence problem for the lasso algorithm with alpha = 0 and recommend using the OLS model. For comparison, OLS regression is fitted and yields slightly better MSE and R suqared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "491a686b-b83a-47dc-9c19-6be8410d657f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 1.00002011e+00 -2.73876324e-04 -3.34075327e-04]\n",
      "Mean Squared Error: 0.0009619501643116172\n",
      "R squared: 0.9990105552987837\n"
     ]
    }
   ],
   "source": [
    "# Initializing linear model\n",
    "ols = LinearRegression()\n",
    "\n",
    "# Model training\n",
    "ols.fit(X_std_train, y_std_train)\n",
    "\n",
    "# Computing predictions with test data\n",
    "y_std_pred_ols = ols.predict(X_std_test)\n",
    "\n",
    "# Compute MSE and R2 squared\n",
    "mse = mean_squared_error(y_std_test, y_std_pred_ols)\n",
    "r2_squared = r2_score(y_std_test, y_std_pred_ols)\n",
    "\n",
    "# Print results\n",
    "print(\"Coefficients: {}\".format(ols.coef_))\n",
    "print(\"Mean Squared Error: {}\".format(mse))\n",
    "print(\"R squared: {}\".format(r2_squared))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
